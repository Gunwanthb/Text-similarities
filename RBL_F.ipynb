{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "Main_sentence = \"A compiler is a special program that processes statements written in a high level language to machine level language\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_headline1 = \"A compiler is a special program that processes statements written in a high level language to machine level language\"\n",
    "news_headline2 = \"A compiler is a program that processes high level language to machine level language\"\n",
    "news_headline3 = \"A compiler is of high level language to machine level language\"\n",
    "news_headline4 = \"Both apple and orange are fruit\"\n",
    "\n",
    "news_headlines = [news_headline1, news_headline2, news_headline3, news_headline4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokens of the sentences: \n",
      "\n",
      "\n",
      " ['A', 'compiler', 'is', 'a', 'special', 'program', 'that', 'processes', 'statements', 'written', 'in', 'a', 'high', 'level', 'language', 'to', 'machine', 'level', 'language']\n",
      "tokens of the sentences: \n",
      "\n",
      "\n",
      " ['A', 'compiler', 'is', 'a', 'program', 'that', 'processes', 'high', 'level', 'language', 'to', 'machine', 'level', 'language']\n",
      "tokens of the sentences: \n",
      "\n",
      "\n",
      " ['A', 'compiler', 'is', 'of', 'high', 'level', 'language', 'to', 'machine', 'level', 'language']\n",
      "tokens of the sentences: \n",
      "\n",
      "\n",
      " ['Both', 'apple', 'and', 'orange', 'are', 'fruit']\n"
     ]
    }
   ],
   "source": [
    "news_headline1_tokens = nltk.word_tokenize(news_headline1)\n",
    "news_headline2_tokens = nltk.word_tokenize(news_headline2)\n",
    "news_headline3_tokens = nltk.word_tokenize(news_headline3)\n",
    "news_headline4_tokens = nltk.word_tokenize(news_headline4)\n",
    "for words in [news_headline1_tokens, news_headline2_tokens, news_headline3_tokens, news_headline4_tokens]:\n",
    "    print('tokens of the sentences: \\n\\n\\n', words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "All Tokens:\n",
      "['A', 'compiler', 'is', 'a', 'special', 'program', 'that', 'processes', 'statements', 'written', 'in', 'a', 'high', 'level', 'language', 'to', 'machine', 'level', 'language', 'A', 'compiler', 'is', 'a', 'program', 'that', 'processes', 'high', 'level', 'language', 'to', 'machine', 'level', 'language', 'A', 'compiler', 'is', 'of', 'high', 'level', 'language', 'to', 'machine', 'level', 'language', 'Both', 'apple', 'and', 'orange', 'are', 'fruit']\n",
      "\n",
      "Original Input: ['A', 'compiler', 'is', 'a', 'special', 'program', 'that', 'processes', 'statements', 'written', 'in', 'a', 'high', 'level', 'language', 'to', 'machine', 'level', 'language']\n",
      "Encoded by Label Encoder: [ 0  6 10  2 18 17 20 16 19 22  9  2  8 12 11 21 13 12 11]\n",
      "Encoded by OneHot Encoder:\n",
      "  (0, 0)\t1.0\n",
      "  (1, 6)\t1.0\n",
      "  (2, 10)\t1.0\n",
      "  (3, 2)\t1.0\n",
      "  (4, 18)\t1.0\n",
      "  (5, 17)\t1.0\n",
      "  (6, 20)\t1.0\n",
      "  (7, 16)\t1.0\n",
      "  (8, 19)\t1.0\n",
      "  (9, 22)\t1.0\n",
      "  (10, 9)\t1.0\n",
      "  (11, 2)\t1.0\n",
      "  (12, 8)\t1.0\n",
      "  (13, 12)\t1.0\n",
      "  (14, 11)\t1.0\n",
      "  (15, 21)\t1.0\n",
      "  (16, 13)\t1.0\n",
      "  (17, 12)\t1.0\n",
      "  (18, 11)\t1.0\n",
      "\n",
      "Original Input: ['A', 'compiler', 'is', 'a', 'program', 'that', 'processes', 'high', 'level', 'language', 'to', 'machine', 'level', 'language']\n",
      "Encoded by Label Encoder: [ 0  6 10  2 17 20 16  8 12 11 21 13 12 11]\n",
      "Encoded by OneHot Encoder:\n",
      "  (0, 0)\t1.0\n",
      "  (1, 6)\t1.0\n",
      "  (2, 10)\t1.0\n",
      "  (3, 2)\t1.0\n",
      "  (4, 17)\t1.0\n",
      "  (5, 20)\t1.0\n",
      "  (6, 16)\t1.0\n",
      "  (7, 8)\t1.0\n",
      "  (8, 12)\t1.0\n",
      "  (9, 11)\t1.0\n",
      "  (10, 21)\t1.0\n",
      "  (11, 13)\t1.0\n",
      "  (12, 12)\t1.0\n",
      "  (13, 11)\t1.0\n",
      "\n",
      "Original Input: ['A', 'compiler', 'is', 'of', 'high', 'level', 'language', 'to', 'machine', 'level', 'language']\n",
      "Encoded by Label Encoder: [ 0  6 10 14  8 12 11 21 13 12 11]\n",
      "Encoded by OneHot Encoder:\n",
      "  (0, 0)\t1.0\n",
      "  (1, 6)\t1.0\n",
      "  (2, 10)\t1.0\n",
      "  (3, 14)\t1.0\n",
      "  (4, 8)\t1.0\n",
      "  (5, 12)\t1.0\n",
      "  (6, 11)\t1.0\n",
      "  (7, 21)\t1.0\n",
      "  (8, 13)\t1.0\n",
      "  (9, 12)\t1.0\n",
      "  (10, 11)\t1.0\n",
      "\n",
      "Original Input: ['Both', 'apple', 'and', 'orange', 'are', 'fruit']\n",
      "Encoded by Label Encoder: [ 1  4  3 15  5  7]\n",
      "Encoded by OneHot Encoder:\n",
      "  (0, 1)\t1.0\n",
      "  (1, 4)\t1.0\n",
      "  (2, 3)\t1.0\n",
      "  (3, 15)\t1.0\n",
      "  (4, 5)\t1.0\n",
      "  (5, 7)\t1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HELLO\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from numpy import argmax\n",
    "\n",
    "def transform(headlines):\n",
    "    tokens = [w for s in headlines for w in s ]\n",
    "    print()\n",
    "    print('All Tokens:')\n",
    "    print(tokens)\n",
    "\n",
    "    results = []\n",
    "    label_enc = sklearn.preprocessing.LabelEncoder()\n",
    "    onehot_enc = sklearn.preprocessing.OneHotEncoder()\n",
    "    \n",
    "    encoded_all_tokens = label_enc.fit_transform(list(set(tokens)))\n",
    "    encoded_all_tokens = encoded_all_tokens.reshape(len(encoded_all_tokens), 1)\n",
    "    \n",
    "    onehot_enc.fit(encoded_all_tokens)\n",
    "    \n",
    "    for headline_tokens in headlines:\n",
    "        print()\n",
    "        print('Original Input:', headline_tokens)\n",
    "        \n",
    "        encoded_words = label_enc.transform(headline_tokens)\n",
    "        print('Encoded by Label Encoder:', encoded_words)\n",
    "        \n",
    "        encoded_words = onehot_enc.transform(encoded_words.reshape(len(encoded_words), 1))\n",
    "        print('Encoded by OneHot Encoder:')\n",
    "        print(encoded_words)\n",
    "\n",
    "        results.append(np.sum(encoded_words.toarray(), axis=0))\n",
    "    \n",
    "    return results\n",
    "\n",
    "transformed_results = transform([\n",
    "    news_headline1_tokens, news_headline2_tokens, news_headline3_tokens, news_headline4_tokens])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Master Sentence: A compiler is a special program that processes statements written in a high level language to machine level language\n",
      "-----\n",
      "Score: 0.00, Comparing Sentence: A compiler is a special program that processes statements written in a high level language to machine level language\n",
      "-----\n",
      "Score: 2.24, Comparing Sentence: A compiler is a program that processes high level language to machine level language\n",
      "-----\n",
      "Score: 3.46, Comparing Sentence: A compiler is of high level language to machine level language\n",
      "-----\n",
      "Score: 5.57, Comparing Sentence: Both apple and orange are fruit\n"
     ]
    }
   ],
   "source": [
    "print('Master Sentence: %s' % news_headlines[0])\n",
    "for i, news_headline in enumerate(news_headlines):\n",
    "    score = sklearn.metrics.pairwise.euclidean_distances([transformed_results[i]], [transformed_results[0]])[0][0]\n",
    "    print('-----')\n",
    "    print('Score: %.2f, Comparing Sentence: %s' % (score, news_headline))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Master Sentence: A compiler is a special program that processes statements written in a high level language to machine level language\n",
      "-----\n",
      "Score: 1.00, Comparing Sentence: A compiler is a special program that processes statements written in a high level language to machine level language\n",
      "-----\n",
      "Score: 0.25, Comparing Sentence: A compiler is a program that processes high level language to machine level language\n",
      "-----\n",
      "Score: 0.06, Comparing Sentence: A compiler is of high level language to machine level language\n",
      "-----\n",
      "Score: 0.00, Comparing Sentence: Both apple and orange are fruit\n"
     ]
    }
   ],
   "source": [
    "def calculate_position(values):\n",
    "    x = []\n",
    "    for pos, matrix in enumerate(values):\n",
    "        if matrix > 0:\n",
    "            x.append(pos)\n",
    "    return x\n",
    "\n",
    "\"\"\"\n",
    "    Since scikit-learn can only compare same number of dimension of input. \n",
    "    Add padding to the shortest sentence.\n",
    "\"\"\"\n",
    "def padding(sentence1, sentence2):\n",
    "    x1 = sentence1.copy()\n",
    "    x2 = sentence2.copy()\n",
    "    \n",
    "    diff = len(x1) - len(x2)\n",
    "    \n",
    "    if diff > 0:\n",
    "        for i in range(0, diff):\n",
    "            x2.append(-1)\n",
    "    elif diff < 0:\n",
    "        for i in range(0, abs(diff)):\n",
    "            x1.append(-1)\n",
    "    \n",
    "    return x1, x2    \n",
    "\n",
    "y_actual = calculate_position(transformed_results[0])\n",
    "\n",
    "print('Master Sentence: %s' % news_headlines[0])\n",
    "for i, news_headline in enumerate(news_headlines):\n",
    "    y_compare = calculate_position(transformed_results[i])\n",
    "    x1, x2 = padding(y_actual, y_compare)\n",
    "    score = sklearn.metrics.jaccard_similarity_score(x1, x2)\n",
    "    print('-----')\n",
    "    print('Score: %.2f, Comparing Sentence: %s' % (score, news_headline))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import PorterStemmer\n",
    "ps = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A  :  A\n",
      "compiler  :  compil\n",
      "is  :  is\n",
      "a  :  a\n",
      "special  :  special\n",
      "program  :  program\n",
      "that  :  that\n",
      "processes  :  process\n",
      "statements  :  statement\n",
      "written  :  written\n",
      "in  :  in\n",
      "a  :  a\n",
      "high  :  high\n",
      "level  :  level\n",
      "language  :  languag\n",
      "to  :  to\n",
      "machine  :  machin\n",
      "level  :  level\n",
      "language  :  languag\n"
     ]
    }
   ],
   "source": [
    "# importing modules \n",
    "from nltk.stem import PorterStemmer \n",
    "from nltk.tokenize import word_tokenize \n",
    "\n",
    "ps = PorterStemmer() \n",
    "se = \"A compiler is a special program that processes statements written in a high level language to machine level language\"\n",
    "# sentence = \"Elon Musks Boring Co to build high speed airport link in Chicago\"\n",
    "wd = word_tokenize(se) \n",
    "\n",
    "for w in wd: \n",
    "\tprint(w, \" : \", ps.stem(w)) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A', 'compiler', 'is', 'a', 'special', 'program', 'that', 'processes', 'statements', 'written', 'in', 'a', 'high', 'level', 'language', 'to', 'machine', 'level', 'language'] \n",
      " \n",
      "\n",
      "A compiler is a special program that process statement written in a high level language to machine level language\n"
     ]
    }
   ],
   "source": [
    "word_list = nltk.word_tokenize(se)\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "print(word_list,'\\n','\\n')\n",
    "lemmatized_output = ' '.join([lemmatizer.lemmatize(w) for w in word_list])\n",
    "print(lemmatized_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Master Sentence: A compiler is a special program that processes statements written in a high level language to machine level language\n",
      "-----\n",
      "Score: 1.00, Comparing Sentence: A compiler is a special program that processes statements written in a high level language to machine level language\n",
      "-----\n",
      "Score: 0.90, Comparing Sentence: A compiler is a program that processes high level language to machine level language\n",
      "-----\n",
      "Score: 0.72, Comparing Sentence: A compiler is of high level language to machine level language\n",
      "-----\n",
      "Score: 0.00, Comparing Sentence: Both apple and orange are fruit\n"
     ]
    }
   ],
   "source": [
    "print('Master Sentence: %s' % news_headlines[0])\n",
    "for i, news_headline in enumerate(news_headlines):\n",
    "    score = sklearn.metrics.pairwise.cosine_similarity([transformed_results[i]], [transformed_results[0]])[0][0]\n",
    "    print('-----')\n",
    "    print('Score: %.2f, Comparing Sentence: %s' % (score, news_headline))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
